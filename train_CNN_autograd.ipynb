{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(1000, 1, 28, 28) (1000, 10)\n",
      "(1000, 1, 28, 28) (1000, 10)\n",
      "(10000, 1, 28, 28) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "from MLP_autograd import *\n",
    "from CNN_autograd import *\n",
    "from keras.datasets import mnist\n",
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()\n",
    "\n",
    "def one_hot(Y):\n",
    "  one_hot_Y = np.zeros((Y.size,np.max(Y) + 1))\n",
    "  one_hot_Y[np.arange(Y.size),Y] = 1\n",
    "  return one_hot_Y\n",
    "\n",
    "print(y_train.shape)\n",
    "\n",
    "y_train = one_hot(y_train)\n",
    "y_test = one_hot(y_test)\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "x_validation = x_train[59000:60000]\n",
    "y_validation = y_train[59000:60000,:]\n",
    "x_train = x_train[0:1000]\n",
    "y_train = y_train[0:1000,:]\n",
    "\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0],1,28,28)\n",
    "x_validation = x_validation.reshape(x_validation.shape[0],1,28,28)\n",
    "x_test = x_test.reshape(x_test.shape[0],1,28,28)\n",
    "\n",
    "print(x_train.shape,y_train.shape)\n",
    "print(x_validation.shape, y_validation.shape)\n",
    "print(x_test.shape,y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train:  (1000, 1, 28, 28)\n",
      "y_train:  (1000, 10)\n",
      "x_val:  (1000, 1, 28, 28)\n",
      "y_val:  (1000, 10)\n",
      "epochs:  0 loss_train:  11.660397084609277 accuracy_train: 0.108 loss_val 11.2267773155034 accuracy_validation: 0.146\n",
      "epochs:  1 loss_train:  10.916986547256087 accuracy_train: 0.151 loss_val 10.627423550901467 accuracy_validation: 0.169\n",
      "epochs:  2 loss_train:  10.479233307021564 accuracy_train: 0.163 loss_val 10.331757187990522 accuracy_validation: 0.173\n",
      "epochs:  3 loss_train:  10.190034998638327 accuracy_train: 0.164 loss_val 10.116258058822352 accuracy_validation: 0.173\n",
      "epochs:  4 loss_train:  9.842698734723918 accuracy_train: 0.169 loss_val 9.953911927681078 accuracy_validation: 0.177\n",
      "epochs:  5 loss_train:  9.462934791089507 accuracy_train: 0.184 loss_val 9.737815243511552 accuracy_validation: 0.188\n",
      "epochs:  6 loss_train:  9.255678566814444 accuracy_train: 0.197 loss_val 9.527009618004614 accuracy_validation: 0.187\n",
      "epochs:  7 loss_train:  9.07257497339137 accuracy_train: 0.211 loss_val 9.323494548794619 accuracy_validation: 0.188\n",
      "epochs:  8 loss_train:  8.832348581113001 accuracy_train: 0.213 loss_val 9.083780247225505 accuracy_validation: 0.207\n",
      "epochs:  9 loss_train:  8.566210494718907 accuracy_train: 0.232 loss_val 8.858701055119854 accuracy_validation: 0.211\n",
      "epochs:  10 loss_train:  8.342877075264845 accuracy_train: 0.242 loss_val 8.688350085529237 accuracy_validation: 0.218\n",
      "epochs:  11 loss_train:  8.12719727755176 accuracy_train: 0.251 loss_val 8.528737210752812 accuracy_validation: 0.223\n",
      "epochs:  12 loss_train:  7.906158095392068 accuracy_train: 0.259 loss_val 8.366390707975432 accuracy_validation: 0.227\n",
      "epochs:  13 loss_train:  7.7009316490626505 accuracy_train: 0.266 loss_val 8.195640264992564 accuracy_validation: 0.231\n",
      "epochs:  14 loss_train:  7.513458540673162 accuracy_train: 0.27 loss_val 8.02322206776589 accuracy_validation: 0.241\n",
      "epochs:  15 loss_train:  7.339120159385211 accuracy_train: 0.274 loss_val 7.8724591048360395 accuracy_validation: 0.248\n",
      "epochs:  16 loss_train:  7.172554181153604 accuracy_train: 0.291 loss_val 7.717306866012248 accuracy_validation: 0.254\n",
      "epochs:  17 loss_train:  7.000553752802562 accuracy_train: 0.3 loss_val 7.5564402680200375 accuracy_validation: 0.265\n",
      "epochs:  18 loss_train:  6.830810965587025 accuracy_train: 0.309 loss_val 7.397262650801955 accuracy_validation: 0.276\n",
      "epochs:  19 loss_train:  6.671414745026295 accuracy_train: 0.311 loss_val 7.252467621209403 accuracy_validation: 0.277\n",
      "epochs:  20 loss_train:  6.514986926441069 accuracy_train: 0.32 loss_val 7.111929226825853 accuracy_validation: 0.283\n",
      "epochs:  21 loss_train:  6.358046970895084 accuracy_train: 0.327 loss_val 6.967786357793487 accuracy_validation: 0.289\n",
      "epochs:  22 loss_train:  6.203638964006777 accuracy_train: 0.329 loss_val 6.831100801650064 accuracy_validation: 0.296\n",
      "epochs:  23 loss_train:  6.0577482830348455 accuracy_train: 0.337 loss_val 6.698320757566613 accuracy_validation: 0.305\n",
      "epochs:  24 loss_train:  5.916113492028629 accuracy_train: 0.353 loss_val 6.5739616039778666 accuracy_validation: 0.313\n",
      "epochs:  25 loss_train:  5.785310970669596 accuracy_train: 0.356 loss_val 6.459871310128768 accuracy_validation: 0.324\n",
      "epochs:  26 loss_train:  5.654986254790693 accuracy_train: 0.37 loss_val 6.348315777167347 accuracy_validation: 0.323\n",
      "epochs:  27 loss_train:  5.532055467992123 accuracy_train: 0.374 loss_val 6.240650295451887 accuracy_validation: 0.33\n",
      "epochs:  28 loss_train:  5.416900707663166 accuracy_train: 0.376 loss_val 6.139238181688724 accuracy_validation: 0.341\n",
      "epochs:  29 loss_train:  5.307402934648611 accuracy_train: 0.385 loss_val 6.047787016462358 accuracy_validation: 0.354\n",
      "epochs:  30 loss_train:  5.19791523465281 accuracy_train: 0.392 loss_val 5.950062737865404 accuracy_validation: 0.36\n",
      "epochs:  31 loss_train:  5.098027324994001 accuracy_train: 0.399 loss_val 5.866792440423323 accuracy_validation: 0.37\n",
      "epochs:  32 loss_train:  4.99974109163135 accuracy_train: 0.407 loss_val 5.77998103194816 accuracy_validation: 0.375\n",
      "epochs:  33 loss_train:  4.905829050651289 accuracy_train: 0.412 loss_val 5.701215249884552 accuracy_validation: 0.378\n",
      "epochs:  34 loss_train:  4.8151880780056855 accuracy_train: 0.421 loss_val 5.625230787068372 accuracy_validation: 0.382\n",
      "epochs:  35 loss_train:  4.729926285768995 accuracy_train: 0.419 loss_val 5.549116255698274 accuracy_validation: 0.386\n",
      "epochs:  36 loss_train:  4.647540384839308 accuracy_train: 0.423 loss_val 5.475323815569413 accuracy_validation: 0.391\n",
      "epochs:  37 loss_train:  4.565467055960769 accuracy_train: 0.428 loss_val 5.403997300805791 accuracy_validation: 0.396\n",
      "epochs:  38 loss_train:  4.489648288274118 accuracy_train: 0.428 loss_val 5.338809291621503 accuracy_validation: 0.398\n",
      "epochs:  39 loss_train:  4.415286536592073 accuracy_train: 0.434 loss_val 5.274271574027677 accuracy_validation: 0.398\n",
      "epochs:  40 loss_train:  4.339929125590761 accuracy_train: 0.435 loss_val 5.207911745069757 accuracy_validation: 0.401\n",
      "epochs:  41 loss_train:  4.266494934210885 accuracy_train: 0.437 loss_val 5.139814278045268 accuracy_validation: 0.404\n",
      "epochs:  42 loss_train:  4.192653627083537 accuracy_train: 0.438 loss_val 5.073761005530005 accuracy_validation: 0.409\n",
      "epochs:  43 loss_train:  4.1227175815730535 accuracy_train: 0.439 loss_val 5.014000072804694 accuracy_validation: 0.413\n",
      "epochs:  44 loss_train:  4.053350391091621 accuracy_train: 0.442 loss_val 4.95227470624352 accuracy_validation: 0.418\n",
      "epochs:  45 loss_train:  3.9895157173826683 accuracy_train: 0.446 loss_val 4.895628127016519 accuracy_validation: 0.424\n",
      "epochs:  46 loss_train:  3.9253967099645566 accuracy_train: 0.449 loss_val 4.839182636256019 accuracy_validation: 0.425\n",
      "epochs:  47 loss_train:  3.8657835583602203 accuracy_train: 0.457 loss_val 4.790292616355216 accuracy_validation: 0.425\n",
      "epochs:  48 loss_train:  3.80825509775297 accuracy_train: 0.467 loss_val 4.7411438164960895 accuracy_validation: 0.426\n",
      "epochs:  49 loss_train:  3.75317154790725 accuracy_train: 0.471 loss_val 4.692944924244991 accuracy_validation: 0.429\n",
      "epochs:  50 loss_train:  3.7026260509539624 accuracy_train: 0.474 loss_val 4.64749401062011 accuracy_validation: 0.431\n",
      "epochs:  51 loss_train:  3.6536558937194576 accuracy_train: 0.477 loss_val 4.604771579526679 accuracy_validation: 0.432\n",
      "epochs:  52 loss_train:  3.6039148683176916 accuracy_train: 0.479 loss_val 4.560815911753397 accuracy_validation: 0.437\n",
      "epochs:  53 loss_train:  3.5563247879784234 accuracy_train: 0.481 loss_val 4.517045974571618 accuracy_validation: 0.44\n",
      "epochs:  54 loss_train:  3.5078288747581268 accuracy_train: 0.482 loss_val 4.471241344539471 accuracy_validation: 0.445\n",
      "epochs:  55 loss_train:  3.460541494905039 accuracy_train: 0.484 loss_val 4.423999280951015 accuracy_validation: 0.443\n",
      "epochs:  56 loss_train:  3.4154029873404332 accuracy_train: 0.487 loss_val 4.377120925417835 accuracy_validation: 0.447\n",
      "epochs:  57 loss_train:  3.3728325557192385 accuracy_train: 0.492 loss_val 4.337068748899284 accuracy_validation: 0.448\n",
      "epochs:  58 loss_train:  3.329921768078519 accuracy_train: 0.497 loss_val 4.295445415662925 accuracy_validation: 0.449\n",
      "epochs:  59 loss_train:  3.288964088486793 accuracy_train: 0.503 loss_val 4.255217087957805 accuracy_validation: 0.451\n",
      "epochs:  60 loss_train:  3.2473963377640715 accuracy_train: 0.506 loss_val 4.213390231177579 accuracy_validation: 0.453\n",
      "epochs:  61 loss_train:  3.2068396769710525 accuracy_train: 0.509 loss_val 4.171673801547871 accuracy_validation: 0.455\n",
      "epochs:  62 loss_train:  3.169250947945361 accuracy_train: 0.516 loss_val 4.1349026561172995 accuracy_validation: 0.455\n",
      "epochs:  63 loss_train:  3.1307536427559772 accuracy_train: 0.521 loss_val 4.094974882098881 accuracy_validation: 0.457\n",
      "epochs:  64 loss_train:  3.0912103957081007 accuracy_train: 0.522 loss_val 4.051797163249254 accuracy_validation: 0.46\n",
      "epochs:  65 loss_train:  3.0545050625526757 accuracy_train: 0.531 loss_val 4.012459368104887 accuracy_validation: 0.466\n",
      "epochs:  66 loss_train:  3.019838604652584 accuracy_train: 0.533 loss_val 3.9750406262043643 accuracy_validation: 0.469\n",
      "epochs:  67 loss_train:  2.9838070149483427 accuracy_train: 0.541 loss_val 3.9374804556287497 accuracy_validation: 0.472\n",
      "epochs:  68 loss_train:  2.949820961683236 accuracy_train: 0.545 loss_val 3.9004665703294514 accuracy_validation: 0.473\n",
      "epochs:  69 loss_train:  2.9179899100971807 accuracy_train: 0.552 loss_val 3.8657032685977115 accuracy_validation: 0.477\n",
      "epochs:  70 loss_train:  2.885782857784072 accuracy_train: 0.553 loss_val 3.8309172887812966 accuracy_validation: 0.477\n",
      "epochs:  71 loss_train:  2.8536559487057422 accuracy_train: 0.551 loss_val 3.7952343567842237 accuracy_validation: 0.48\n",
      "epochs:  72 loss_train:  2.823450509166933 accuracy_train: 0.555 loss_val 3.766173813909448 accuracy_validation: 0.483\n",
      "epochs:  73 loss_train:  2.7944716939032364 accuracy_train: 0.556 loss_val 3.736216667105666 accuracy_validation: 0.484\n",
      "epochs:  74 loss_train:  2.7654811123919507 accuracy_train: 0.558 loss_val 3.706358420399761 accuracy_validation: 0.486\n",
      "epochs:  75 loss_train:  2.734296747121282 accuracy_train: 0.559 loss_val 3.674354782016399 accuracy_validation: 0.487\n",
      "epochs:  76 loss_train:  2.707203918151328 accuracy_train: 0.562 loss_val 3.6449880696860575 accuracy_validation: 0.487\n",
      "epochs:  77 loss_train:  2.6798876096210877 accuracy_train: 0.564 loss_val 3.61668687249136 accuracy_validation: 0.489\n",
      "epochs:  78 loss_train:  2.652042189399204 accuracy_train: 0.566 loss_val 3.58702726857901 accuracy_validation: 0.493\n",
      "epochs:  79 loss_train:  2.626078085287572 accuracy_train: 0.567 loss_val 3.558670659185145 accuracy_validation: 0.494\n",
      "epochs:  80 loss_train:  2.599578991428213 accuracy_train: 0.569 loss_val 3.5288376737484626 accuracy_validation: 0.497\n",
      "epochs:  81 loss_train:  2.5731610339647104 accuracy_train: 0.569 loss_val 3.5023879056983125 accuracy_validation: 0.501\n",
      "epochs:  82 loss_train:  2.5493257196307706 accuracy_train: 0.57 loss_val 3.4774399761382484 accuracy_validation: 0.501\n",
      "epochs:  83 loss_train:  2.5210210912112028 accuracy_train: 0.573 loss_val 3.4485398188683316 accuracy_validation: 0.502\n",
      "epochs:  84 loss_train:  2.4959551242793254 accuracy_train: 0.575 loss_val 3.4213370382246495 accuracy_validation: 0.502\n",
      "epochs:  85 loss_train:  2.4728421244378707 accuracy_train: 0.577 loss_val 3.3959455484621666 accuracy_validation: 0.502\n",
      "epochs:  86 loss_train:  2.4492501242756326 accuracy_train: 0.578 loss_val 3.3699140914200063 accuracy_validation: 0.506\n",
      "epochs:  87 loss_train:  2.4250607988106436 accuracy_train: 0.58 loss_val 3.344237960707513 accuracy_validation: 0.506\n",
      "epochs:  88 loss_train:  2.4028723792841284 accuracy_train: 0.581 loss_val 3.318764173561343 accuracy_validation: 0.506\n",
      "epochs:  89 loss_train:  2.3803727457967656 accuracy_train: 0.585 loss_val 3.293906486418663 accuracy_validation: 0.509\n",
      "epochs:  90 loss_train:  2.3568413069945136 accuracy_train: 0.587 loss_val 3.2681226986573093 accuracy_validation: 0.51\n",
      "epochs:  91 loss_train:  2.334276818610819 accuracy_train: 0.591 loss_val 3.2433512742863586 accuracy_validation: 0.512\n",
      "epochs:  92 loss_train:  2.3123540616171168 accuracy_train: 0.593 loss_val 3.219922780470649 accuracy_validation: 0.513\n",
      "epochs:  93 loss_train:  2.289420847276029 accuracy_train: 0.59 loss_val 3.194340617571457 accuracy_validation: 0.515\n",
      "epochs:  94 loss_train:  2.2677988562593 accuracy_train: 0.591 loss_val 3.171717137759883 accuracy_validation: 0.515\n",
      "epochs:  95 loss_train:  2.246809023223702 accuracy_train: 0.598 loss_val 3.1495871014190797 accuracy_validation: 0.514\n",
      "epochs:  96 loss_train:  2.2237164109038376 accuracy_train: 0.597 loss_val 3.1261039471231014 accuracy_validation: 0.517\n",
      "epochs:  97 loss_train:  2.204144536699795 accuracy_train: 0.599 loss_val 3.1045220503667235 accuracy_validation: 0.52\n",
      "epochs:  98 loss_train:  2.186782811487754 accuracy_train: 0.6 loss_val 3.0849964241230317 accuracy_validation: 0.523\n",
      "epochs:  99 loss_train:  2.1663421511793155 accuracy_train: 0.603 loss_val 3.060845259444803 accuracy_validation: 0.526\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.428294414424434, 0.4837)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN1 = Convolutional(input_shape = (1,28,28), kernel_size = 3, output_depth = 4, l_rate = 0.01, activeFuncion = \"relu\")\n",
    "pool1 = MaxPoolingLayer(2)\n",
    "CNN2 = Convolutional(input_shape = (4,13,13), kernel_size = 3,output_depth = 8, l_rate = 0.01, activeFuncion = \"relu\")\n",
    "pool2 = MaxPoolingLayer(2)\n",
    "flatten = Flattening()\n",
    "nn = NeuralNetwork(layers_size=[288,10],activations = [\"softmax\"], lossFunction = \"crossEntropy\", l_rate = 0.01) # 8*6*6 = 288\n",
    "\n",
    "\n",
    "model = Model([CNN1,pool1,CNN2,pool2, flatten,nn])\n",
    "model.train(x_train,y_train,x_validation,y_validation, batch_size = 64, epochs = 100)\n",
    "model.test(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train:  (1000, 1, 28, 28)\n",
      "y_train:  (1000, 10)\n",
      "x_val:  (1000, 1, 28, 28)\n",
      "y_val:  (1000, 10)\n",
      "epochs:  0 loss_train:  2.1478017172479142 accuracy_train: 0.6 loss_val 3.040670716193919 accuracy_validation: 0.529\n",
      "epochs:  1 loss_train:  2.1235179360632896 accuracy_train: 0.607 loss_val 3.0153046995143775 accuracy_validation: 0.533\n",
      "epochs:  2 loss_train:  2.103614430505155 accuracy_train: 0.608 loss_val 2.993787103005355 accuracy_validation: 0.533\n",
      "epochs:  3 loss_train:  2.082173559899423 accuracy_train: 0.611 loss_val 2.9703897025893244 accuracy_validation: 0.536\n",
      "epochs:  4 loss_train:  2.062837475207918 accuracy_train: 0.611 loss_val 2.9498864043203556 accuracy_validation: 0.536\n",
      "epochs:  5 loss_train:  2.0442206104593197 accuracy_train: 0.612 loss_val 2.930642868556625 accuracy_validation: 0.537\n",
      "epochs:  6 loss_train:  2.0265471131638937 accuracy_train: 0.613 loss_val 2.9113918132409617 accuracy_validation: 0.537\n",
      "epochs:  7 loss_train:  2.010283305356826 accuracy_train: 0.616 loss_val 2.8934022800659593 accuracy_validation: 0.544\n",
      "epochs:  8 loss_train:  1.9911241333048724 accuracy_train: 0.618 loss_val 2.873682761395116 accuracy_validation: 0.551\n",
      "epochs:  9 loss_train:  1.9728538184294282 accuracy_train: 0.623 loss_val 2.8543631580980335 accuracy_validation: 0.553\n",
      "epochs:  10 loss_train:  1.9565132331271848 accuracy_train: 0.622 loss_val 2.8375708554358448 accuracy_validation: 0.553\n",
      "epochs:  11 loss_train:  1.9381703485553583 accuracy_train: 0.626 loss_val 2.8178158022079054 accuracy_validation: 0.556\n",
      "epochs:  12 loss_train:  1.9226479320882013 accuracy_train: 0.628 loss_val 2.800025384604046 accuracy_validation: 0.559\n",
      "epochs:  13 loss_train:  1.906372341501335 accuracy_train: 0.629 loss_val 2.7826780677875633 accuracy_validation: 0.56\n",
      "epochs:  14 loss_train:  1.891827923152493 accuracy_train: 0.633 loss_val 2.76598759138565 accuracy_validation: 0.561\n",
      "epochs:  15 loss_train:  1.8770966040339607 accuracy_train: 0.631 loss_val 2.7504672349586476 accuracy_validation: 0.563\n",
      "epochs:  16 loss_train:  1.8612654407307578 accuracy_train: 0.632 loss_val 2.734220604015046 accuracy_validation: 0.563\n",
      "epochs:  17 loss_train:  1.8457532490794093 accuracy_train: 0.634 loss_val 2.7175953527096866 accuracy_validation: 0.564\n",
      "epochs:  18 loss_train:  1.8298381122217608 accuracy_train: 0.635 loss_val 2.6993825708158106 accuracy_validation: 0.564\n",
      "epochs:  19 loss_train:  1.814496092187854 accuracy_train: 0.638 loss_val 2.6836005466614195 accuracy_validation: 0.564\n",
      "epochs:  20 loss_train:  1.7992541165265643 accuracy_train: 0.641 loss_val 2.667782748341484 accuracy_validation: 0.567\n",
      "epochs:  21 loss_train:  1.7851400298417326 accuracy_train: 0.642 loss_val 2.652533284261621 accuracy_validation: 0.569\n",
      "epochs:  22 loss_train:  1.7697710893116814 accuracy_train: 0.644 loss_val 2.6361598550644567 accuracy_validation: 0.572\n",
      "epochs:  23 loss_train:  1.754903053931019 accuracy_train: 0.644 loss_val 2.620521089574288 accuracy_validation: 0.573\n",
      "epochs:  24 loss_train:  1.741232903881061 accuracy_train: 0.647 loss_val 2.6049685512253764 accuracy_validation: 0.575\n",
      "epochs:  25 loss_train:  1.727492679058075 accuracy_train: 0.645 loss_val 2.589612045835612 accuracy_validation: 0.575\n",
      "epochs:  26 loss_train:  1.7136091196323642 accuracy_train: 0.648 loss_val 2.5740099730467145 accuracy_validation: 0.576\n",
      "epochs:  27 loss_train:  1.6990728307742862 accuracy_train: 0.649 loss_val 2.5590198951580994 accuracy_validation: 0.577\n",
      "epochs:  28 loss_train:  1.686098069854734 accuracy_train: 0.649 loss_val 2.5451777367904964 accuracy_validation: 0.577\n",
      "epochs:  29 loss_train:  1.6730911968147588 accuracy_train: 0.651 loss_val 2.531132159832281 accuracy_validation: 0.579\n",
      "epochs:  30 loss_train:  1.6604291868360184 accuracy_train: 0.652 loss_val 2.5172757669479324 accuracy_validation: 0.58\n",
      "epochs:  31 loss_train:  1.6477635351701274 accuracy_train: 0.654 loss_val 2.503360771244938 accuracy_validation: 0.58\n",
      "epochs:  32 loss_train:  1.6351426141353886 accuracy_train: 0.655 loss_val 2.489462446707555 accuracy_validation: 0.579\n",
      "epochs:  33 loss_train:  1.623959924992806 accuracy_train: 0.656 loss_val 2.476589542864465 accuracy_validation: 0.579\n",
      "epochs:  34 loss_train:  1.6122166777121563 accuracy_train: 0.659 loss_val 2.464164432869181 accuracy_validation: 0.58\n",
      "epochs:  35 loss_train:  1.6001593086276824 accuracy_train: 0.662 loss_val 2.450928505448242 accuracy_validation: 0.579\n",
      "epochs:  36 loss_train:  1.5901157472716576 accuracy_train: 0.66 loss_val 2.4384189540890313 accuracy_validation: 0.579\n",
      "epochs:  37 loss_train:  1.5783921724151817 accuracy_train: 0.659 loss_val 2.4250418086282672 accuracy_validation: 0.578\n",
      "epochs:  38 loss_train:  1.567272035421484 accuracy_train: 0.664 loss_val 2.4124440174566235 accuracy_validation: 0.578\n",
      "epochs:  39 loss_train:  1.5561532951975623 accuracy_train: 0.666 loss_val 2.3991938574387413 accuracy_validation: 0.578\n",
      "epochs:  40 loss_train:  1.54527182475025 accuracy_train: 0.669 loss_val 2.3867655312647442 accuracy_validation: 0.578\n",
      "epochs:  41 loss_train:  1.5350641257825877 accuracy_train: 0.673 loss_val 2.374630104208101 accuracy_validation: 0.582\n",
      "epochs:  42 loss_train:  1.5239849807954142 accuracy_train: 0.676 loss_val 2.3626712507017618 accuracy_validation: 0.582\n",
      "epochs:  43 loss_train:  1.5140586711806094 accuracy_train: 0.679 loss_val 2.351536995684049 accuracy_validation: 0.584\n",
      "epochs:  44 loss_train:  1.5038378905863232 accuracy_train: 0.68 loss_val 2.3399401833182005 accuracy_validation: 0.585\n",
      "epochs:  45 loss_train:  1.4964037281812739 accuracy_train: 0.68 loss_val 2.3308029113885347 accuracy_validation: 0.585\n",
      "epochs:  46 loss_train:  1.485604036017957 accuracy_train: 0.681 loss_val 2.3188785084896235 accuracy_validation: 0.585\n",
      "epochs:  47 loss_train:  1.476541169818499 accuracy_train: 0.681 loss_val 2.3084911563990165 accuracy_validation: 0.585\n",
      "epochs:  48 loss_train:  1.4670398163258302 accuracy_train: 0.682 loss_val 2.297565176859128 accuracy_validation: 0.588\n",
      "epochs:  49 loss_train:  1.4587851437398638 accuracy_train: 0.683 loss_val 2.287336116950376 accuracy_validation: 0.588\n",
      "epochs:  50 loss_train:  1.4499153355225127 accuracy_train: 0.684 loss_val 2.2775676191519634 accuracy_validation: 0.589\n",
      "epochs:  51 loss_train:  1.4406230188353244 accuracy_train: 0.686 loss_val 2.2667870600095013 accuracy_validation: 0.59\n",
      "epochs:  52 loss_train:  1.431982533049683 accuracy_train: 0.687 loss_val 2.256962352771717 accuracy_validation: 0.591\n",
      "epochs:  53 loss_train:  1.4227790115262722 accuracy_train: 0.691 loss_val 2.246543555126251 accuracy_validation: 0.592\n",
      "epochs:  54 loss_train:  1.4138506346967223 accuracy_train: 0.692 loss_val 2.236860307762905 accuracy_validation: 0.595\n",
      "epochs:  55 loss_train:  1.4050847841079077 accuracy_train: 0.692 loss_val 2.226960344635074 accuracy_validation: 0.593\n",
      "epochs:  56 loss_train:  1.3963402967325884 accuracy_train: 0.693 loss_val 2.217206294729847 accuracy_validation: 0.592\n",
      "epochs:  57 loss_train:  1.3880292120173359 accuracy_train: 0.694 loss_val 2.2074090763338345 accuracy_validation: 0.595\n",
      "epochs:  58 loss_train:  1.3804484376703008 accuracy_train: 0.694 loss_val 2.1979659717627835 accuracy_validation: 0.596\n",
      "epochs:  59 loss_train:  1.373086013509675 accuracy_train: 0.695 loss_val 2.1891223697710482 accuracy_validation: 0.598\n",
      "epochs:  60 loss_train:  1.3651872116954846 accuracy_train: 0.695 loss_val 2.1795809412140112 accuracy_validation: 0.6\n",
      "epochs:  61 loss_train:  1.3572125477413386 accuracy_train: 0.698 loss_val 2.1698993523256718 accuracy_validation: 0.601\n",
      "epochs:  62 loss_train:  1.349520343474867 accuracy_train: 0.697 loss_val 2.1610697991817567 accuracy_validation: 0.603\n",
      "epochs:  63 loss_train:  1.3425594036773096 accuracy_train: 0.698 loss_val 2.15275773861482 accuracy_validation: 0.605\n",
      "epochs:  64 loss_train:  1.3344290919064627 accuracy_train: 0.7 loss_val 2.143528834782606 accuracy_validation: 0.605\n",
      "epochs:  65 loss_train:  1.3268536827514348 accuracy_train: 0.702 loss_val 2.1344864429930097 accuracy_validation: 0.605\n",
      "epochs:  66 loss_train:  1.3195079069645916 accuracy_train: 0.706 loss_val 2.1263975567720994 accuracy_validation: 0.605\n",
      "epochs:  67 loss_train:  1.3122365683680335 accuracy_train: 0.705 loss_val 2.1172657413791796 accuracy_validation: 0.605\n",
      "epochs:  68 loss_train:  1.3054076610249883 accuracy_train: 0.707 loss_val 2.109448389352191 accuracy_validation: 0.606\n",
      "epochs:  69 loss_train:  1.2986392451681266 accuracy_train: 0.707 loss_val 2.1016808958631374 accuracy_validation: 0.606\n",
      "epochs:  70 loss_train:  1.2914665703863397 accuracy_train: 0.707 loss_val 2.093604612919091 accuracy_validation: 0.607\n",
      "epochs:  71 loss_train:  1.2862968354530537 accuracy_train: 0.706 loss_val 2.0872126558807267 accuracy_validation: 0.607\n",
      "epochs:  72 loss_train:  1.2788638569542512 accuracy_train: 0.706 loss_val 2.079279177393129 accuracy_validation: 0.608\n",
      "epochs:  73 loss_train:  1.2726578267882227 accuracy_train: 0.707 loss_val 2.071908593481129 accuracy_validation: 0.61\n",
      "epochs:  74 loss_train:  1.2656581496297414 accuracy_train: 0.706 loss_val 2.0642420911036403 accuracy_validation: 0.609\n",
      "epochs:  75 loss_train:  1.2593016023381747 accuracy_train: 0.706 loss_val 2.056461299859896 accuracy_validation: 0.612\n",
      "epochs:  76 loss_train:  1.2517582892793058 accuracy_train: 0.706 loss_val 2.0482178147482446 accuracy_validation: 0.613\n",
      "epochs:  77 loss_train:  1.246456568565973 accuracy_train: 0.707 loss_val 2.0411706954855102 accuracy_validation: 0.613\n",
      "epochs:  78 loss_train:  1.2401905667239348 accuracy_train: 0.71 loss_val 2.033099004089605 accuracy_validation: 0.617\n",
      "epochs:  79 loss_train:  1.2316842791662261 accuracy_train: 0.712 loss_val 2.0237592505956634 accuracy_validation: 0.617\n",
      "epochs:  80 loss_train:  1.2263374053592835 accuracy_train: 0.713 loss_val 2.016458028132904 accuracy_validation: 0.617\n",
      "epochs:  81 loss_train:  1.2196254288894373 accuracy_train: 0.714 loss_val 2.008212067952942 accuracy_validation: 0.619\n",
      "epochs:  82 loss_train:  1.213869887126994 accuracy_train: 0.716 loss_val 2.000893037916232 accuracy_validation: 0.621\n",
      "epochs:  83 loss_train:  1.2079778420199805 accuracy_train: 0.714 loss_val 1.9937633054511374 accuracy_validation: 0.625\n",
      "epochs:  84 loss_train:  1.2023821701510435 accuracy_train: 0.716 loss_val 1.986869265868076 accuracy_validation: 0.625\n",
      "epochs:  85 loss_train:  1.195897307843294 accuracy_train: 0.717 loss_val 1.979086616247878 accuracy_validation: 0.627\n",
      "epochs:  86 loss_train:  1.1902302158573361 accuracy_train: 0.718 loss_val 1.9714749982262452 accuracy_validation: 0.628\n",
      "epochs:  87 loss_train:  1.185503517560109 accuracy_train: 0.72 loss_val 1.9664272841041508 accuracy_validation: 0.628\n",
      "epochs:  88 loss_train:  1.1791037451837516 accuracy_train: 0.72 loss_val 1.9586437344611412 accuracy_validation: 0.628\n",
      "epochs:  89 loss_train:  1.1743704288643477 accuracy_train: 0.723 loss_val 1.9521548890041656 accuracy_validation: 0.629\n",
      "epochs:  90 loss_train:  1.1689988893041419 accuracy_train: 0.725 loss_val 1.9454852291794074 accuracy_validation: 0.629\n",
      "epochs:  91 loss_train:  1.1639490392335505 accuracy_train: 0.726 loss_val 1.9390470306808736 accuracy_validation: 0.63\n",
      "epochs:  92 loss_train:  1.1584972479518472 accuracy_train: 0.725 loss_val 1.9322847481228314 accuracy_validation: 0.63\n",
      "epochs:  93 loss_train:  1.1533043856883403 accuracy_train: 0.725 loss_val 1.9255076764645702 accuracy_validation: 0.631\n",
      "epochs:  94 loss_train:  1.1479738915857576 accuracy_train: 0.725 loss_val 1.919052488595427 accuracy_validation: 0.632\n",
      "epochs:  95 loss_train:  1.14221958169887 accuracy_train: 0.727 loss_val 1.91229647760426 accuracy_validation: 0.632\n",
      "epochs:  96 loss_train:  1.1380561300921972 accuracy_train: 0.726 loss_val 1.9066947222767294 accuracy_validation: 0.632\n",
      "epochs:  97 loss_train:  1.1326376894159198 accuracy_train: 0.725 loss_val 1.899775256909378 accuracy_validation: 0.633\n",
      "epochs:  98 loss_train:  1.126788011179188 accuracy_train: 0.724 loss_val 1.8934829014576222 accuracy_validation: 0.634\n",
      "epochs:  99 loss_train:  1.1222233002203192 accuracy_train: 0.725 loss_val 1.8876064570266429 accuracy_validation: 0.635\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.2485272175364135, 0.577)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(x_train,y_train,x_validation,y_validation, batch_size = 64, epochs = 100)\n",
    "model.test(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train:  (1000, 1, 28, 28)\n",
      "y_train:  (1000, 10)\n",
      "x_val:  (1000, 1, 28, 28)\n",
      "y_val:  (1000, 10)\n",
      "epochs:  0 loss_train:  1.1172568297398922 accuracy_train: 0.726 loss_val 1.8813453298867506 accuracy_validation: 0.635\n",
      "epochs:  1 loss_train:  1.113148644041712 accuracy_train: 0.726 loss_val 1.8764333010170782 accuracy_validation: 0.636\n",
      "epochs:  2 loss_train:  1.1071568984698035 accuracy_train: 0.726 loss_val 1.8689987277743505 accuracy_validation: 0.636\n",
      "epochs:  3 loss_train:  1.1024986547824296 accuracy_train: 0.726 loss_val 1.8638691934919207 accuracy_validation: 0.636\n",
      "epochs:  4 loss_train:  1.0976830437476819 accuracy_train: 0.726 loss_val 1.8577461024783934 accuracy_validation: 0.638\n",
      "epochs:  5 loss_train:  1.0920720307513319 accuracy_train: 0.726 loss_val 1.8510949193273751 accuracy_validation: 0.64\n",
      "epochs:  6 loss_train:  1.0882647371126013 accuracy_train: 0.726 loss_val 1.8460758229288772 accuracy_validation: 0.638\n",
      "epochs:  7 loss_train:  1.0839229185767658 accuracy_train: 0.73 loss_val 1.8411270011571406 accuracy_validation: 0.64\n",
      "epochs:  8 loss_train:  1.0791087869815292 accuracy_train: 0.73 loss_val 1.8354792563790199 accuracy_validation: 0.641\n",
      "epochs:  9 loss_train:  1.0744031272669645 accuracy_train: 0.733 loss_val 1.8295534872745405 accuracy_validation: 0.641\n",
      "epochs:  10 loss_train:  1.0703373029169299 accuracy_train: 0.733 loss_val 1.824157634619385 accuracy_validation: 0.642\n",
      "epochs:  11 loss_train:  1.0652686183516042 accuracy_train: 0.732 loss_val 1.8179165567174098 accuracy_validation: 0.641\n",
      "epochs:  12 loss_train:  1.0618387985704634 accuracy_train: 0.735 loss_val 1.8135209827741876 accuracy_validation: 0.643\n",
      "epochs:  13 loss_train:  1.0574651376845576 accuracy_train: 0.736 loss_val 1.8084069519657586 accuracy_validation: 0.644\n",
      "epochs:  14 loss_train:  1.0532824020674283 accuracy_train: 0.736 loss_val 1.8028789023710945 accuracy_validation: 0.644\n",
      "epochs:  15 loss_train:  1.0492552856331963 accuracy_train: 0.737 loss_val 1.7979968864446327 accuracy_validation: 0.644\n",
      "epochs:  16 loss_train:  1.0447000551647048 accuracy_train: 0.738 loss_val 1.7924384672578335 accuracy_validation: 0.643\n",
      "epochs:  17 loss_train:  1.0404871383152068 accuracy_train: 0.74 loss_val 1.78754242642202 accuracy_validation: 0.644\n",
      "epochs:  18 loss_train:  1.0366901358807172 accuracy_train: 0.739 loss_val 1.782343875245851 accuracy_validation: 0.644\n",
      "epochs:  19 loss_train:  1.031370771040186 accuracy_train: 0.739 loss_val 1.7765658912937665 accuracy_validation: 0.646\n",
      "epochs:  20 loss_train:  1.0276800249987181 accuracy_train: 0.74 loss_val 1.7720748020309207 accuracy_validation: 0.646\n",
      "epochs:  21 loss_train:  1.0227623616403145 accuracy_train: 0.741 loss_val 1.7662707146563654 accuracy_validation: 0.647\n",
      "epochs:  22 loss_train:  1.0186394718043839 accuracy_train: 0.74 loss_val 1.7611813366113056 accuracy_validation: 0.648\n",
      "epochs:  23 loss_train:  1.0151607826671667 accuracy_train: 0.741 loss_val 1.7566498794417262 accuracy_validation: 0.648\n",
      "epochs:  24 loss_train:  1.0106266593792184 accuracy_train: 0.743 loss_val 1.7511368047685727 accuracy_validation: 0.648\n",
      "epochs:  25 loss_train:  1.0064763256567948 accuracy_train: 0.74 loss_val 1.7461704837787175 accuracy_validation: 0.649\n",
      "epochs:  26 loss_train:  1.0027612514071027 accuracy_train: 0.742 loss_val 1.7413547344154012 accuracy_validation: 0.65\n",
      "epochs:  27 loss_train:  0.9980955497758854 accuracy_train: 0.741 loss_val 1.7357490745154824 accuracy_validation: 0.651\n",
      "epochs:  28 loss_train:  0.9940179379184593 accuracy_train: 0.742 loss_val 1.7308274635499614 accuracy_validation: 0.651\n",
      "epochs:  29 loss_train:  0.9903950490706014 accuracy_train: 0.743 loss_val 1.7261125986688455 accuracy_validation: 0.651\n",
      "epochs:  30 loss_train:  0.9861008527873775 accuracy_train: 0.744 loss_val 1.7211070267245954 accuracy_validation: 0.65\n",
      "epochs:  31 loss_train:  0.9824218455206137 accuracy_train: 0.744 loss_val 1.7163446376492606 accuracy_validation: 0.65\n",
      "epochs:  32 loss_train:  0.9785058440064779 accuracy_train: 0.744 loss_val 1.7109902111122741 accuracy_validation: 0.651\n",
      "epochs:  33 loss_train:  0.9746811559599826 accuracy_train: 0.744 loss_val 1.7062442201710992 accuracy_validation: 0.65\n",
      "epochs:  34 loss_train:  0.9708446094105638 accuracy_train: 0.744 loss_val 1.7014767776711082 accuracy_validation: 0.65\n",
      "epochs:  35 loss_train:  0.9672048594735726 accuracy_train: 0.745 loss_val 1.696995762117025 accuracy_validation: 0.65\n",
      "epochs:  36 loss_train:  0.9629003143823481 accuracy_train: 0.745 loss_val 1.6921340280460795 accuracy_validation: 0.65\n",
      "epochs:  37 loss_train:  0.9598134106683669 accuracy_train: 0.746 loss_val 1.6876914357891184 accuracy_validation: 0.651\n",
      "epochs:  38 loss_train:  0.9559145945595059 accuracy_train: 0.747 loss_val 1.6828513985134768 accuracy_validation: 0.651\n",
      "epochs:  39 loss_train:  0.9523404839714605 accuracy_train: 0.748 loss_val 1.6787079862701255 accuracy_validation: 0.652\n",
      "epochs:  40 loss_train:  0.9476518213118049 accuracy_train: 0.748 loss_val 1.6736772039393677 accuracy_validation: 0.654\n",
      "epochs:  41 loss_train:  0.9442276008947724 accuracy_train: 0.748 loss_val 1.6697679578040807 accuracy_validation: 0.656\n",
      "epochs:  42 loss_train:  0.9407070050406449 accuracy_train: 0.748 loss_val 1.6652510484035714 accuracy_validation: 0.657\n",
      "epochs:  43 loss_train:  0.9370565271078908 accuracy_train: 0.748 loss_val 1.6610686337489646 accuracy_validation: 0.656\n",
      "epochs:  44 loss_train:  0.9337178339699983 accuracy_train: 0.748 loss_val 1.65677550276274 accuracy_validation: 0.656\n",
      "epochs:  45 loss_train:  0.9299934252715674 accuracy_train: 0.749 loss_val 1.652334966594083 accuracy_validation: 0.657\n",
      "epochs:  46 loss_train:  0.9267236858052154 accuracy_train: 0.75 loss_val 1.6486631250469492 accuracy_validation: 0.657\n",
      "epochs:  47 loss_train:  0.9236071794532019 accuracy_train: 0.751 loss_val 1.6445916370759022 accuracy_validation: 0.657\n",
      "epochs:  48 loss_train:  0.9199878246564929 accuracy_train: 0.752 loss_val 1.6407243546900072 accuracy_validation: 0.657\n",
      "epochs:  49 loss_train:  0.9171082616798502 accuracy_train: 0.752 loss_val 1.6372925677643357 accuracy_validation: 0.657\n",
      "epochs:  50 loss_train:  0.9131808955023973 accuracy_train: 0.75 loss_val 1.6330394554682832 accuracy_validation: 0.658\n",
      "epochs:  51 loss_train:  0.9101044242409022 accuracy_train: 0.751 loss_val 1.6291527587192685 accuracy_validation: 0.659\n",
      "epochs:  52 loss_train:  0.9067655783852845 accuracy_train: 0.752 loss_val 1.6253379302117106 accuracy_validation: 0.66\n",
      "epochs:  53 loss_train:  0.9036845528216887 accuracy_train: 0.751 loss_val 1.6216877489982522 accuracy_validation: 0.658\n",
      "epochs:  54 loss_train:  0.9002704569486586 accuracy_train: 0.753 loss_val 1.6178906632318233 accuracy_validation: 0.659\n",
      "epochs:  55 loss_train:  0.8971574897097234 accuracy_train: 0.753 loss_val 1.6145752008449747 accuracy_validation: 0.66\n",
      "epochs:  56 loss_train:  0.8938797009126519 accuracy_train: 0.756 loss_val 1.610869387466929 accuracy_validation: 0.661\n",
      "epochs:  57 loss_train:  0.8908374217894433 accuracy_train: 0.758 loss_val 1.6072282134150406 accuracy_validation: 0.66\n",
      "epochs:  58 loss_train:  0.8875723415207617 accuracy_train: 0.758 loss_val 1.6033571505096464 accuracy_validation: 0.663\n",
      "epochs:  59 loss_train:  0.884400902552327 accuracy_train: 0.76 loss_val 1.600303026629203 accuracy_validation: 0.664\n",
      "epochs:  60 loss_train:  0.8815891182237681 accuracy_train: 0.759 loss_val 1.5966525437636045 accuracy_validation: 0.664\n",
      "epochs:  61 loss_train:  0.8783950390916827 accuracy_train: 0.761 loss_val 1.5932638782153772 accuracy_validation: 0.665\n",
      "epochs:  62 loss_train:  0.8753340881900876 accuracy_train: 0.761 loss_val 1.589778801391028 accuracy_validation: 0.665\n",
      "epochs:  63 loss_train:  0.8721259165290055 accuracy_train: 0.762 loss_val 1.5867615551311172 accuracy_validation: 0.666\n",
      "epochs:  64 loss_train:  0.8692321384877518 accuracy_train: 0.761 loss_val 1.5834315172371793 accuracy_validation: 0.665\n",
      "epochs:  65 loss_train:  0.8666131545071762 accuracy_train: 0.761 loss_val 1.5805452668360587 accuracy_validation: 0.664\n",
      "epochs:  66 loss_train:  0.8638589650345199 accuracy_train: 0.762 loss_val 1.576798111559698 accuracy_validation: 0.667\n",
      "epochs:  67 loss_train:  0.8611739699418891 accuracy_train: 0.763 loss_val 1.5739844225956166 accuracy_validation: 0.667\n",
      "epochs:  68 loss_train:  0.8579244043690863 accuracy_train: 0.765 loss_val 1.5711509752795283 accuracy_validation: 0.668\n",
      "epochs:  69 loss_train:  0.8550147435922194 accuracy_train: 0.766 loss_val 1.5670442506300906 accuracy_validation: 0.668\n",
      "epochs:  70 loss_train:  0.8525993774843854 accuracy_train: 0.767 loss_val 1.5650430132187754 accuracy_validation: 0.667\n",
      "epochs:  71 loss_train:  0.8492695054922524 accuracy_train: 0.769 loss_val 1.560957903741994 accuracy_validation: 0.668\n",
      "epochs:  72 loss_train:  0.8463419960018198 accuracy_train: 0.771 loss_val 1.5582183612351583 accuracy_validation: 0.668\n",
      "epochs:  73 loss_train:  0.8440577291349097 accuracy_train: 0.771 loss_val 1.5559725219682194 accuracy_validation: 0.669\n",
      "epochs:  74 loss_train:  0.8407877720303454 accuracy_train: 0.771 loss_val 1.5526179477934114 accuracy_validation: 0.669\n",
      "epochs:  75 loss_train:  0.8383660125797632 accuracy_train: 0.772 loss_val 1.5498688904634141 accuracy_validation: 0.669\n",
      "epochs:  76 loss_train:  0.8352295667733476 accuracy_train: 0.772 loss_val 1.546421516309183 accuracy_validation: 0.669\n",
      "epochs:  77 loss_train:  0.8326272835332259 accuracy_train: 0.774 loss_val 1.543516200126202 accuracy_validation: 0.669\n",
      "epochs:  78 loss_train:  0.8297128683859241 accuracy_train: 0.775 loss_val 1.5407014871273066 accuracy_validation: 0.673\n",
      "epochs:  79 loss_train:  0.8268121810978354 accuracy_train: 0.776 loss_val 1.5374090875522015 accuracy_validation: 0.671\n",
      "epochs:  80 loss_train:  0.8246880031222336 accuracy_train: 0.778 loss_val 1.5355067666702098 accuracy_validation: 0.672\n",
      "epochs:  81 loss_train:  0.8218587560941557 accuracy_train: 0.778 loss_val 1.532183776097742 accuracy_validation: 0.671\n",
      "epochs:  82 loss_train:  0.8189035282873655 accuracy_train: 0.778 loss_val 1.529265692919127 accuracy_validation: 0.672\n",
      "epochs:  83 loss_train:  0.8164078017715003 accuracy_train: 0.778 loss_val 1.527143189647772 accuracy_validation: 0.673\n",
      "epochs:  84 loss_train:  0.8137849863797626 accuracy_train: 0.779 loss_val 1.5238919045107924 accuracy_validation: 0.673\n",
      "epochs:  85 loss_train:  0.8115162435649209 accuracy_train: 0.779 loss_val 1.5213946947448098 accuracy_validation: 0.673\n",
      "epochs:  86 loss_train:  0.8085524837119221 accuracy_train: 0.78 loss_val 1.5184148821466965 accuracy_validation: 0.674\n",
      "epochs:  87 loss_train:  0.8059266525514117 accuracy_train: 0.779 loss_val 1.514981439962188 accuracy_validation: 0.673\n",
      "epochs:  88 loss_train:  0.8037675048587276 accuracy_train: 0.781 loss_val 1.5131495801222936 accuracy_validation: 0.675\n",
      "epochs:  89 loss_train:  0.8012408357348391 accuracy_train: 0.781 loss_val 1.510461859251702 accuracy_validation: 0.674\n",
      "epochs:  90 loss_train:  0.7989065881341006 accuracy_train: 0.784 loss_val 1.5069515553876953 accuracy_validation: 0.674\n",
      "epochs:  91 loss_train:  0.7965754318175174 accuracy_train: 0.783 loss_val 1.5049117526266693 accuracy_validation: 0.676\n",
      "epochs:  92 loss_train:  0.7937760946115113 accuracy_train: 0.784 loss_val 1.5016757011309312 accuracy_validation: 0.676\n",
      "epochs:  93 loss_train:  0.7915463422769806 accuracy_train: 0.784 loss_val 1.4987587622242686 accuracy_validation: 0.676\n",
      "epochs:  94 loss_train:  0.7890022011888365 accuracy_train: 0.784 loss_val 1.4964854727836852 accuracy_validation: 0.676\n",
      "epochs:  95 loss_train:  0.7865980118786435 accuracy_train: 0.785 loss_val 1.4935220285409714 accuracy_validation: 0.679\n",
      "epochs:  96 loss_train:  0.7844756184172336 accuracy_train: 0.785 loss_val 1.4910341721766935 accuracy_validation: 0.679\n",
      "epochs:  97 loss_train:  0.7816923452836648 accuracy_train: 0.786 loss_val 1.4881989845335628 accuracy_validation: 0.679\n",
      "epochs:  98 loss_train:  0.7797554184979583 accuracy_train: 0.787 loss_val 1.4858036370905794 accuracy_validation: 0.679\n",
      "epochs:  99 loss_train:  0.7773449106137128 accuracy_train: 0.787 loss_val 1.4834487562573389 accuracy_validation: 0.679\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.7953899424471678, 0.624)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(x_train,y_train,x_validation,y_validation, batch_size = 64, epochs = 100)\n",
    "model.test(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train:  (1000, 1, 28, 28)\n",
      "y_train:  (1000, 10)\n",
      "x_val:  (1000, 1, 28, 28)\n",
      "y_val:  (1000, 10)\n",
      "epochs:  0 loss_train:  0.774672698140634 accuracy_train: 0.788 loss_val 1.4804486865764215 accuracy_validation: 0.68\n",
      "epochs:  1 loss_train:  0.7725060163156455 accuracy_train: 0.789 loss_val 1.4786179499877699 accuracy_validation: 0.681\n",
      "epochs:  2 loss_train:  0.7704288447271124 accuracy_train: 0.79 loss_val 1.4759545070532374 accuracy_validation: 0.681\n",
      "epochs:  3 loss_train:  0.7681234079569984 accuracy_train: 0.79 loss_val 1.4736814072225175 accuracy_validation: 0.681\n",
      "epochs:  4 loss_train:  0.7658426317889586 accuracy_train: 0.791 loss_val 1.471156504763075 accuracy_validation: 0.682\n",
      "epochs:  5 loss_train:  0.763283803891671 accuracy_train: 0.79 loss_val 1.4683641237974805 accuracy_validation: 0.682\n",
      "epochs:  6 loss_train:  0.7611683771004119 accuracy_train: 0.789 loss_val 1.4658804894779087 accuracy_validation: 0.682\n",
      "epochs:  7 loss_train:  0.7592132335398685 accuracy_train: 0.789 loss_val 1.4638757321068356 accuracy_validation: 0.682\n",
      "epochs:  8 loss_train:  0.7565495286900062 accuracy_train: 0.791 loss_val 1.4607604759196202 accuracy_validation: 0.683\n",
      "epochs:  9 loss_train:  0.7544469010775865 accuracy_train: 0.792 loss_val 1.4582181079586494 accuracy_validation: 0.685\n",
      "epochs:  10 loss_train:  0.7522678412038694 accuracy_train: 0.793 loss_val 1.4561024617365448 accuracy_validation: 0.685\n",
      "epochs:  11 loss_train:  0.750071495953081 accuracy_train: 0.793 loss_val 1.4533895069012805 accuracy_validation: 0.688\n",
      "epochs:  12 loss_train:  0.7480269535425607 accuracy_train: 0.793 loss_val 1.4512450267373846 accuracy_validation: 0.688\n",
      "epochs:  13 loss_train:  0.7461884623887901 accuracy_train: 0.794 loss_val 1.4485546534961187 accuracy_validation: 0.691\n",
      "epochs:  14 loss_train:  0.7437851026830963 accuracy_train: 0.794 loss_val 1.446119353683852 accuracy_validation: 0.688\n",
      "epochs:  15 loss_train:  0.7420254382261403 accuracy_train: 0.796 loss_val 1.4438948338339985 accuracy_validation: 0.691\n",
      "epochs:  16 loss_train:  0.7395792188251424 accuracy_train: 0.796 loss_val 1.4414795483673506 accuracy_validation: 0.691\n",
      "epochs:  17 loss_train:  0.7376178387313147 accuracy_train: 0.797 loss_val 1.4385795809448878 accuracy_validation: 0.693\n",
      "epochs:  18 loss_train:  0.7355214353976438 accuracy_train: 0.796 loss_val 1.4367241012837029 accuracy_validation: 0.691\n",
      "epochs:  19 loss_train:  0.733626666489308 accuracy_train: 0.797 loss_val 1.434027130517313 accuracy_validation: 0.692\n",
      "epochs:  20 loss_train:  0.7316226215504444 accuracy_train: 0.797 loss_val 1.4321537084221576 accuracy_validation: 0.692\n",
      "epochs:  21 loss_train:  0.7293173401522087 accuracy_train: 0.798 loss_val 1.429970681238666 accuracy_validation: 0.692\n",
      "epochs:  22 loss_train:  0.7273705594696273 accuracy_train: 0.798 loss_val 1.4274206038843016 accuracy_validation: 0.694\n",
      "epochs:  23 loss_train:  0.7252030226537581 accuracy_train: 0.798 loss_val 1.4250791612509024 accuracy_validation: 0.696\n",
      "epochs:  24 loss_train:  0.7234649798086962 accuracy_train: 0.798 loss_val 1.4235272805451895 accuracy_validation: 0.697\n",
      "epochs:  25 loss_train:  0.7210645144940118 accuracy_train: 0.801 loss_val 1.4210149842822446 accuracy_validation: 0.699\n",
      "epochs:  26 loss_train:  0.7195071194423835 accuracy_train: 0.798 loss_val 1.4197223833981016 accuracy_validation: 0.698\n",
      "epochs:  27 loss_train:  0.7167480928188846 accuracy_train: 0.804 loss_val 1.4173449563689897 accuracy_validation: 0.699\n",
      "epochs:  28 loss_train:  0.715060162966526 accuracy_train: 0.802 loss_val 1.4158356120841935 accuracy_validation: 0.699\n",
      "epochs:  29 loss_train:  0.7134826956362216 accuracy_train: 0.802 loss_val 1.4135025836978248 accuracy_validation: 0.699\n",
      "epochs:  30 loss_train:  0.7114312675992129 accuracy_train: 0.803 loss_val 1.4119678406930407 accuracy_validation: 0.699\n",
      "epochs:  31 loss_train:  0.7090994928910807 accuracy_train: 0.804 loss_val 1.4098945863280656 accuracy_validation: 0.7\n",
      "epochs:  32 loss_train:  0.7074898575045023 accuracy_train: 0.803 loss_val 1.4083548307050178 accuracy_validation: 0.7\n",
      "epochs:  33 loss_train:  0.7048878625710441 accuracy_train: 0.805 loss_val 1.4056483846597234 accuracy_validation: 0.703\n",
      "epochs:  34 loss_train:  0.7035993775935755 accuracy_train: 0.803 loss_val 1.4043034435184238 accuracy_validation: 0.702\n",
      "epochs:  35 loss_train:  0.7013112446542131 accuracy_train: 0.805 loss_val 1.4022691709909176 accuracy_validation: 0.703\n",
      "epochs:  36 loss_train:  0.6996716143485023 accuracy_train: 0.805 loss_val 1.401482682681474 accuracy_validation: 0.703\n",
      "epochs:  37 loss_train:  0.6974187411639888 accuracy_train: 0.807 loss_val 1.3994441090609886 accuracy_validation: 0.703\n",
      "epochs:  38 loss_train:  0.6953722030844021 accuracy_train: 0.806 loss_val 1.3975533000546585 accuracy_validation: 0.703\n",
      "epochs:  39 loss_train:  0.6939041519965173 accuracy_train: 0.806 loss_val 1.396384866718532 accuracy_validation: 0.704\n",
      "epochs:  40 loss_train:  0.6915312437845214 accuracy_train: 0.808 loss_val 1.3939033646829246 accuracy_validation: 0.703\n",
      "epochs:  41 loss_train:  0.6895615230193504 accuracy_train: 0.807 loss_val 1.3926975121651541 accuracy_validation: 0.707\n",
      "epochs:  42 loss_train:  0.687609117370673 accuracy_train: 0.808 loss_val 1.3901075781392327 accuracy_validation: 0.707\n",
      "epochs:  43 loss_train:  0.6858018408220047 accuracy_train: 0.81 loss_val 1.3882387268005956 accuracy_validation: 0.708\n",
      "epochs:  44 loss_train:  0.6839419856092014 accuracy_train: 0.811 loss_val 1.3864460138738237 accuracy_validation: 0.709\n",
      "epochs:  45 loss_train:  0.6821657271837612 accuracy_train: 0.812 loss_val 1.3848290456689047 accuracy_validation: 0.708\n",
      "epochs:  46 loss_train:  0.6802123809742454 accuracy_train: 0.813 loss_val 1.38248433293948 accuracy_validation: 0.708\n",
      "epochs:  47 loss_train:  0.6784417917845372 accuracy_train: 0.815 loss_val 1.3813056652595055 accuracy_validation: 0.707\n",
      "epochs:  48 loss_train:  0.6764030437549895 accuracy_train: 0.814 loss_val 1.378867886050232 accuracy_validation: 0.708\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_validation\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_validation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mtest(x_test,y_test)\n",
      "File \u001b[1;32mc:\\Users\\dotie\\My tnh\\Multi-layer-Perceptron\\CNN_autograd.py:101\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, x_train, y_train, x_val, y_val, batch_size, epochs)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# if(e % 5 == 0):\u001b[39;00m\n\u001b[0;32m    100\u001b[0m (loss_train, accuracy_train) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest(x_train, y_train)\n\u001b[1;32m--> 101\u001b[0m (loss_val, accuracy_val) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs: \u001b[39m\u001b[38;5;124m\"\u001b[39m, e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss_train: \u001b[39m\u001b[38;5;124m\"\u001b[39m, loss_train, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy_train:\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy_train,\n\u001b[0;32m    103\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss_val\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss_val, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy_validation:\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy_val)\n",
      "File \u001b[1;32mc:\\Users\\dotie\\My tnh\\Multi-layer-Perceptron\\CNN_autograd.py:109\u001b[0m, in \u001b[0;36mModel.test\u001b[1;34m(self, x_test, y_test)\u001b[0m\n\u001b[0;32m    107\u001b[0m output \u001b[38;5;241m=\u001b[39m Tensor(x_test, requires_grad\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layers \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m--> 109\u001b[0m   output \u001b[38;5;241m=\u001b[39m \u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39msum(y_test \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(output\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1e-6\u001b[39m)) \u001b[38;5;241m/\u001b[39m y_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    113\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_accuracy(np\u001b[38;5;241m.\u001b[39margmax(output\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mT,\u001b[38;5;241m0\u001b[39m),np\u001b[38;5;241m.\u001b[39margmax(y_test\u001b[38;5;241m.\u001b[39mT,\u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\dotie\\My tnh\\Multi-layer-Perceptron\\CNN_autograd.py:57\u001b[0m, in \u001b[0;36mMaxPoolingLayer.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m): \u001b[38;5;66;03m# input 4 chiu l 1 tensor\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m   output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaxpooling\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpool_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\dotie\\My tnh\\Multi-layer-Perceptron\\autograd.py:301\u001b[0m, in \u001b[0;36mTensor.maxpooling\u001b[1;34m(self, pool_size)\u001b[0m\n\u001b[0;32m    299\u001b[0m                 w_end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(w_start \u001b[38;5;241m+\u001b[39m pool_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m3\u001b[39m])\n\u001b[0;32m    300\u001b[0m                 \u001b[38;5;28;01mif\u001b[39;00m h_start \u001b[38;5;241m<\u001b[39m h_end \u001b[38;5;129;01mand\u001b[39;00m w_start \u001b[38;5;241m<\u001b[39m w_end:\n\u001b[1;32m--> 301\u001b[0m                     output[n, c, i, j] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_start\u001b[49m\u001b[43m:\u001b[49m\u001b[43mh_end\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_start\u001b[49m\u001b[43m:\u001b[49m\u001b[43mw_end\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m result \u001b[38;5;241m=\u001b[39m Tensor(output, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequires_grad, depends_on\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mself\u001b[39m], operator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaxpool\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_backward\u001b[39m(grad):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train(x_train,y_train,x_validation,y_validation, batch_size = 64, epochs = 100)\n",
    "model.test(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(x_train,y_train,x_validation,y_validation, batch_size = 64, epochs = 100)\n",
    "model.test(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(x_train,y_train,x_validation,y_validation, batch_size = 64, epochs = 100)\n",
    "model.test(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3, 32, 32) (1000, 10)\n",
      "(1000, 3, 32, 32) (1000, 10)\n",
      "(10000, 3, 32, 32) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "from MLP_autograd import *\n",
    "from CNN_autograd import *\n",
    "from keras.datasets import cifar10\n",
    "(x_train,y_train),(x_test,y_test) = cifar10.load_data()\n",
    "x_train = x_train.transpose(0, 3, 1, 2)\n",
    "x_test = x_test.transpose(0, 3, 1, 2)\n",
    "def one_hot(Y):\n",
    "  one_hot_Y = np.zeros((Y.size,np.max(Y) + 1))\n",
    "  one_hot_Y[np.arange(Y.size),Y] = 1\n",
    "  return one_hot_Y\n",
    "\n",
    "\n",
    "y_train = one_hot(y_train.T)\n",
    "y_test = one_hot(y_test)\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "x_validation = x_train[49000:50000]\n",
    "y_validation = y_train[49000:50000,:]\n",
    "x_train = x_train[0:1000]\n",
    "y_train = y_train[0:1000,:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(x_train.shape,y_train.shape)\n",
    "print(x_validation.shape,y_validation.shape)\n",
    "print(x_test.shape,y_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train:  (1000, 3, 32, 32)\n",
      "y_train:  (1000, 10)\n",
      "x_val:  (1000, 3, 32, 32)\n",
      "y_val:  (1000, 10)\n",
      "epochs:  0 loss_train:  11.613791877719578 accuracy_train: 0.105 loss_val 11.518412170549626 accuracy_validation: 0.097\n",
      "epochs:  1 loss_train:  11.302936453837155 accuracy_train: 0.097 loss_val 11.180641131938529 accuracy_validation: 0.104\n",
      "epochs:  2 loss_train:  10.93579199190302 accuracy_train: 0.103 loss_val 10.88995385727677 accuracy_validation: 0.114\n",
      "epochs:  3 loss_train:  10.58942567710182 accuracy_train: 0.111 loss_val 10.53036321554819 accuracy_validation: 0.126\n",
      "epochs:  4 loss_train:  10.212947832940285 accuracy_train: 0.125 loss_val 10.274328810746677 accuracy_validation: 0.125\n",
      "epochs:  5 loss_train:  9.86976117085449 accuracy_train: 0.128 loss_val 10.056808338990384 accuracy_validation: 0.128\n",
      "epochs:  6 loss_train:  9.591825836608008 accuracy_train: 0.127 loss_val 9.791222057948586 accuracy_validation: 0.125\n"
     ]
    }
   ],
   "source": [
    "CNN1 = Convolutional(input_shape = (3,32,32), kernel_size = 3, output_depth = 4, l_rate = 0.01, activeFuncion = \"relu\")\n",
    "pool1 = MaxPoolingLayer(2)\n",
    "CNN2 = Convolutional(input_shape = (4,15,15), kernel_size = 3,output_depth = 8, l_rate = 0.01, activeFuncion = \"relu\")\n",
    "pool2 = MaxPoolingLayer(2)\n",
    "flatten = Flattening()\n",
    "nn = NeuralNetwork(layers_size=[392,10],activations = [\"softmax\"], lossFunction = \"crossEntropy\", l_rate = 0.01) # 8*7*7 = 392\n",
    "\n",
    "\n",
    "model = Model([CNN1,pool1,CNN2,pool2, flatten,nn])\n",
    "model.train(x_train,y_train,x_validation,y_validation, batch_size = 64, epochs = 100)\n",
    "model.test(x_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(x_train,y_train,x_validation,y_validation, batch_size = 64, epochs = 100)\n",
    "model.test(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(x_train,y_train,x_validation,y_validation, batch_size = 64, epochs = 100)\n",
    "model.test(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(x_train,y_train,x_validation,y_validation, batch_size = 64, epochs = 100)\n",
    "model.test(x_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
